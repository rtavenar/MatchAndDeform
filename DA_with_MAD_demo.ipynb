{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of using MAD for Domain Adaptation\n",
    "\n",
    "This notebook illustrates the use of the MAD loss in a domain adaptation setting, as described in the paper.\n",
    "Note that this notebook relies on a simplified adaptation problem coined _TinyTimeMatch_ in order to have a simple-to-reproduce example of our method.\n",
    "TinyTimeMatch is a subsample of the DK1 $\\rightarrow$ AT1 adaptation problem from miniTimeMatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:37:00.795497: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from dataset_loader import load_a_dataset\n",
    "from General_model import CNNMAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the MAD-CNN procedure to train models for domain adaptation for time series classification.\n",
    "\n",
    "Here, we will try to classify series from Austria in the \"MiniTimeMatch\" dataset and we will use for training series from Denmark.\n",
    "For these domains, the corresponding numbers in the dataset are 4 for Austria and 3 for Denmark. \n",
    "They both have 7 classes and the series are composed of 10 features\n",
    "\n",
    "First we have to load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 3\n",
    "target = 4\n",
    "\n",
    "train_source, train_source_label, valid_source, valid_source_label, test_source, test_source_label = load_a_dataset(dataset_name=\"Dataset/TinyTimeMatch/TinyTimeMatch\", domain_id=str(source))\n",
    "train_target, train_target_label, valid_target, valid_target_label, test_target, test_target_label = load_a_dataset(dataset_name=\"Dataset/TinyTimeMatch/TinyTimeMatch\", domain_id=str(target))\n",
    "\n",
    "number_of_features = 10\n",
    "number_of_classes = len(set(train_source_label.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to define the networks we want to use.\n",
    "We need a feature extractor that will be composed of 3 layers and a classifier that will be a single layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=number_of_features, out_channels=128, kernel_size=8, stride=1, padding=\"same\", bias=False),\n",
    "            nn.BatchNorm1d(num_features=128, affine=False),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1, padding=\"same\", bias=False),\n",
    "            nn.BatchNorm1d(num_features=256, affine=False),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=\"same\", bias=False),\n",
    "            nn.BatchNorm1d(num_features=128, affine=False),\n",
    "            nn.ReLU())\n",
    "classifier = nn.Sequential(nn.Linear(128, number_of_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define hyper-parameters such as $\\alpha=0.1$, $\\beta=0.01$, the learning rate $=0.001$ and the batchsize $=256$.\n",
    "We took the values from the papers.\n",
    "\n",
    "We also need to define some paths and names for saving purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = 0.01\n",
    "learning_rate = 0.001\n",
    "batchsize = 256\n",
    "number_of_iterations = 100\n",
    "name_model = \"MAD_demo\"\n",
    "\n",
    "path_save = os.path.join(\"TinyTimeMatch\", \"MAD\", str(alpha), str(beta), str(learning_rate), str(source) + \"_\" + str(target))\n",
    "\n",
    "if os.path.exists(path_save) is False:\n",
    "    os.makedirs(path_save)\n",
    "name = path_save + \"/\" + name_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want weakly supervised learning, we have to find the proportion of each class in the target domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, c = np.unique(train_target_label, return_counts=True)\n",
    "target_prop = c / train_target.shape[0]\n",
    "target_prop = torch.Tensor(target_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batchsize has to be carefully calibrated in case one of the two domains has less series than the batchsize chosen by the user.\n",
    "To make sure everything goes smoothly, the actual batchsize is set to be equal to the minimum between the desired batchsize and the number of series in both domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_size = train_source.shape[0]\n",
    "target_size = train_target.shape[0]\n",
    "batchsize = torch.min(torch.tensor([batchsize, source_size, target_size]))\n",
    "batchsize = batchsize.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the whole MAD-CNN model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_mod = CNNMAD(name=name, \n",
    "                 batchsize=batchsize, \n",
    "                 feature_extractor=feature_extractor, \n",
    "                 classifier=classifier,\n",
    "                 X_target=train_target,\n",
    "\n",
    "                 y_target=train_target_label, \n",
    "                 lr=learning_rate, \n",
    "                 saving=True, #To be set to True if we want to save resutls\n",
    "                 max_iterations=number_of_iterations,\n",
    "                 validation_step=1000,\n",
    "\n",
    "                 target_prop=target_prop, \n",
    "                 alpha=alpha, \n",
    "                 beta=beta, \n",
    "                 MAD_class=True, #To be set to True if we want C-MAD or to False if we want MAD\n",
    "                 save_OT_plan=False,\n",
    "\n",
    "                 save_DTW_matrices=False,\n",
    "                 save_latent_source=False,\n",
    "                 save_latent_target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model over a few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    CNN_mod.fit(X_source=train_source, \n",
    "                y_source=train_source_label,\n",
    "                X_source_valid=valid_source,\n",
    "                y_source_valid=valid_source_label,\n",
    "                X_target_valid=valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we then show the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTimeMatch/MAD/0.1/0.01/0.001/3_4/MAD_demo\n",
      "100 Evaluation set  target :\n",
      "Average loss: 0.0134, Accuracy: 39/140 (27.857%)\n",
      "F1 micro score is :  0.2785714285714286\n",
      "F1 macro score is :  0.222966073697153\n",
      "F1 weigthed score is :  0.222966073697153\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    CNN_mod.evaluate(inputs=test_target, labels=test_target_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the accuracy is not expected to be in the same magnitude as the numbers presented in the paper since the method is run for a small number of epochs on a demo subset of an adaptation problem from miniTimeMatch.\n",
    "\n",
    "Running the exact same experiment outside of a notebook can be done using the following command:\n",
    "\n",
    "```python3 main.py --dataset \"TinyTimeMatch\" --model \"MAD\" --source_id 3 --target_id 4 --alpha 0.1 --beta 0.01 --learning_rate 0.0001 --iteration 10 --name_model \"MAD_demo\" --seed 100 --target_class_proportion \"True\" --batchsize 256 --per_class_dtw \"True\"```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00036dfcc2497e759c7ebcbd7b6dab5fedd6b776a66997d4fce41a30dd58dac7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
